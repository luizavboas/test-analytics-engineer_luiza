{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_learning_curve (estimator, X, y, n_splits, name):\n",
    "    '''\n",
    "        Plots the learning curve for the given classifier, using a k-fold cross validation\n",
    "        with n_splits.\n",
    "\n",
    "        Inputs:\n",
    "            estimator: scikit-learn classifier\n",
    "            X, y: dataset\n",
    "            n_splits: # of folders for k-fold cross validation\n",
    "            name: str: name of the classifier, to use in saving figure\n",
    "    '''\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import learning_curve\n",
    "\n",
    "    n_examples, train_scores, test_scores = learning_curve(estimator = estimator,\n",
    "                                                                X = X,\n",
    "                                                                y = y,\n",
    "                                                                train_sizes = np.linspace(0.1,1.0,20),\n",
    "                                                                cv = n_splits)\n",
    "\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(n_examples, train_mean,\n",
    "                        color='red', marker='*',\n",
    "                        markersize = 2, label='Mean training accuracy')\n",
    "\n",
    "    plt.plot(n_examples, test_mean,\n",
    "                color='blue', marker='s', \n",
    "                markersize = 3, label='Mean validation accuracy',)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('Nº of Data points')\n",
    "    plt.title('Learning Curve '+name)\n",
    "    plt.ylim([0.0, 1.5])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig('LearningCurve '+name+'test.png')\n",
    "    plt.show()\n",
    "\n",
    "def model_validation (estimator, X, y, param_name, param, n_splits, name):\n",
    "    '''\n",
    "        Plots the validation curve for the given classifier, using a k-fold cross validation\n",
    "        with n_splits over the parameter 'param' range.\n",
    "\n",
    "        Inputs:\n",
    "            estimator: scikit-learn classifier\n",
    "            param_name, param: estimator parameter to iterate over\n",
    "            X, y: dataset\n",
    "            n_splits: # of folders for k-fold cross validation\n",
    "            name: str: name of the classifier, to use in saving figure\n",
    "    '''\n",
    "\n",
    "    import matplotlib.pyplot as plt    \n",
    "    from sklearn.model_selection import validation_curve\n",
    "    train_scores, test_scores = validation_curve(estimator = estimator,\n",
    "                                                X = X,\n",
    "                                                y = y,\n",
    "                                                param_name = param_name,\n",
    "                                                param_range = param,\n",
    "                                                cv = n_splits)\n",
    "\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(param, train_mean,\n",
    "            color='red', marker='*',\n",
    "            markersize = 2, label='Mean training accuracy')\n",
    "\n",
    "    plt.plot(param, test_mean,\n",
    "            color='blue', marker='s', \n",
    "            markersize = 3, label='Mean validation accuracy')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xscale('log')\n",
    "    plt.legend(loc='lower right')\n",
    "    xlabel_name = pd.DataFrame(np.array([['Logistic Regression','SVM','Decision Tree','Random Forest','SGD'],\n",
    "                                        ['C','C','Máx. Depth', 'Nº Estimators','Learning Rate']]).T, \n",
    "                                        columns = ['Classifier','Param'])\n",
    "\n",
    "    plt.xlabel(str((xlabel_name[xlabel_name['Classifier']==name]['Param']).values[0]))\n",
    "\n",
    "    plt.ylim([0.0, 1.2])\n",
    "    plt.title('Validation Curve '+name)\n",
    "    plt.ylabel('Accuracy')  \n",
    "    plt.savefig('ValidationCurve'+name+'test.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Loading modules \n",
    "\n",
    "# Preprocessing and splitting modules\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "train_test_split, KFold, GridSearchCV, StratifiedShuffleSplit)\n",
    "\n",
    "# Learnign Algorithms Modules\n",
    "from sklearn.linear_model import (\n",
    "LogisticRegression, SGDClassifier, SGDRegressor)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luiza\\Downloads\\test-analytics-engineer_luiza-1\\notebooks\\ml_training.ipynb Cell 2\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luiza/Downloads/test-analytics-engineer_luiza-1/notebooks/ml_training.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load datasets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luiza/Downloads/test-analytics-engineer_luiza-1/notebooks/ml_training.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_products \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNew_ProdutosVarejos.csv\u001b[39m\u001b[39m\"\u001b[39m, na_values \u001b[39m=\u001b[39m na_vls, nrows \u001b[39m=\u001b[39m nrows)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luiza/Downloads/test-analytics-engineer_luiza-1/notebooks/ml_training.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_clts \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColetas.csv\u001b[39m\u001b[39m\"\u001b[39m, na_values \u001b[39m=\u001b[39m na_vls, nrows \u001b[39m=\u001b[39m nrows)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "# Folder path\n",
    "path =  \"../data/\"\n",
    "\n",
    "# Which values are considered NaN\n",
    "na_vls = ['#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan', \n",
    "               '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan', \n",
    "                'null', '...']\n",
    "\n",
    "# Load datasets\n",
    "df_products = pd.read_csv(path+\"New_ProdutosVarejos.csv\", na_values = na_vls, na_values = na_vls)\n",
    "df_clts = pd.read_csv(path+\"Coletas.csv\", na_values = na_vls, na_values = na_vls,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset dimensions:\n",
    "n_data, n_features = X.shape\n",
    "\n",
    "# Model Selection and Validation Parameters\n",
    "n_splits = 10   # --> # of folders for K-Fold Cross Validation step\n",
    "random_state = 42\n",
    "\n",
    "#nPCA = np.array(np.arange(0, n_features,2))\n",
    "nPCA = np.array([3])\n",
    "\n",
    "# Splitting and Standardization of training and test datasets\n",
    "std = StandardScaler()\n",
    "\n",
    "# Train test splitting\n",
    "test_size = 0.25\n",
    "train_size = 0.75\n",
    "\n",
    "# Stratified data splitting into Train Dataset and Test Dataset\n",
    "sss = StratifiedShuffleSplit(n_splits = 2, test_size = test_size, random_state=random_state)\n",
    "train_index,test_index = sss.split(X, y)\n",
    "\n",
    "X_train = X[train_index[0]]\n",
    "y_train = y[train_index[0]]\n",
    "X_test = X[test_index[0]]\n",
    "y_test = y[test_index[0]]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = random_state)\n",
    "\n",
    "# Data Standardization\n",
    "X_train_std = std.fit_transform(X_train, y_train)\n",
    "X_test_std = std.fit_transform(X_test, y_test)\n",
    "\n",
    "## 3. Chosen estimators\n",
    "LR_estimator = make_pipeline(StandardScaler(), LogisticRegression(\n",
    "                    max_iter = 10000,\n",
    "                    random_state=random_state,))\n",
    "SVC_estimator =  make_pipeline(StandardScaler(), SVC())\n",
    "DT_estimator =   make_pipeline(StandardScaler(), DecisionTreeClassifier())\n",
    "RF_estimator =  make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "SGD_estimator = make_pipeline(StandardScaler(), SGDClassifier())\n",
    "\n",
    "# Grids for the estimators\n",
    "param = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "# Logistic Regression\n",
    "solvers = ['lbfgs','liblinear','newton-cg','newton-cholesky','sag','saga']\n",
    "lr_grid = [{'logisticregression__solver': solvers, 'logisticregression__C':param[0:6]}]\n",
    "\n",
    "# SVM\n",
    "svc_grid = [{'svc__C': param, 'svc__kernel': ['linear']},\n",
    "{'svc__C': param, 'svc__gamma': param, 'svc__kernel': ['rbf']},\n",
    "{'svc__C': param, 'svc__kernel': ['poly'], 'svc__degree': [1,2,3,4]}]\n",
    "\n",
    "# Decision Tree and Random Forest\n",
    "max_depth = [1, 5, 10, 15, 20, 25, 30]\n",
    "n_estimators = [1, 5, 10, 15, 20, 25, 30]\n",
    "dt_grid = [{'decisiontreeclassifier__max_depth': max_depth}]\n",
    "rf_grid = {'randomforestclassifier__max_depth': max_depth, \n",
    "        'randomforestclassifier__n_estimators':n_estimators}\n",
    "\n",
    "#SGD parameters\n",
    "sgd_grid = {'sgdclassifier__learning_rate':['constant', \n",
    "            'optimal','invscaling', 'adaptive'], \n",
    "            'sgdclassifier__eta0':param[0:5]}\n",
    "\n",
    "\n",
    "## 4. Logistic Regression Validation\n",
    "lr_gs = GridSearchCV(estimator = LR_estimator,\n",
    "                    param_grid = lr_grid,\n",
    "                    scoring = 'accuracy',\n",
    "                    cv = n_splits)\n",
    "\n",
    "lr_gs = lr_gs.fit(X_train_std,y_train)\n",
    "    \n",
    "## 5. Support Vector Machine Validation\n",
    "svc_gs = GridSearchCV(estimator = SVC_estimator,\n",
    "                        param_grid = svc_grid,\n",
    "                        scoring = 'accuracy',\n",
    "                        cv = n_splits)\n",
    "\n",
    "svc_gs = svc_gs.fit(X_train_std, y_train)\n",
    "\n",
    "## 6. Decision Tree Validation\n",
    "dt_gs = GridSearchCV(DT_estimator,\n",
    "                    param_grid = dt_grid, \n",
    "                    scoring ='accuracy',\n",
    "                    cv = n_splits)\n",
    "dt_gs = dt_gs.fit(X_train_std, y_train)        \n",
    "\n",
    "## 7. Random Forest Validation\n",
    "rf_gs = GridSearchCV(estimator = RF_estimator,\n",
    "                    param_grid = rf_grid, \n",
    "                    scoring = 'accuracy',\n",
    "                    cv = n_splits)\n",
    "rf_gs = rf_gs.fit(X_train_std, y_train)\n",
    "\n",
    "## 7. SGD Validation\n",
    "sgd_gs = GridSearchCV(estimator = SGD_estimator,\n",
    "                    param_grid = sgd_grid, \n",
    "                    scoring = 'accuracy',\n",
    "                    cv = n_splits)\n",
    "sgd_gs = sgd_gs.fit(X_train_std, y_train)\n",
    "\n",
    "## 8. Classifier and hyperparameters choice\n",
    "print(\"Logistic Regression:\\nScore: \", lr_gs.best_score_,\"\\nBest Param: \", lr_gs.best_params_,\n",
    "\"\\nSupport Vector Machine:\\nScore: \", svc_gs.best_score_, \"\\nBest Param: \", svc_gs.best_params_,\n",
    "\"\\nDecision Tree:\\nScore: \", dt_gs.best_score_, \"\\nBest Param: \", dt_gs.best_params_,\n",
    "\"\\nRandom Forest:\\nScore: \", rf_gs.best_score_, \"\\nBest Param: \", rf_gs.best_params_,\n",
    "\"\\nSGD:\\nScore: \", sgd_gs.best_score_, \"\\nBest Param: \", sgd_gs.best_params_)\n",
    "\n",
    "\n",
    "## 9. Final Accuracy\n",
    "LR_estimator = lr_gs.best_estimator_\n",
    "model_learning_curve(LR_estimator, X_test_std, y_test, \n",
    "                    n_splits,\n",
    "                    'Logistic Regression')\n",
    "\n",
    "SVC_estimator = svc_gs.best_estimator_\n",
    "model_learning_curve(SVC_estimator, X_test_std, y_test, \n",
    "                     n_splits,'SVM')\n",
    "\n",
    "dt_estimator = dt_gs.best_estimator_\n",
    "model_learning_curve(DT_estimator, X_test_std, y_test,\n",
    "                    n_splits, \n",
    "                    'Decision Tree')   \n",
    "\n",
    "RF_estimator = rf_gs.best_estimator_\n",
    "model_learning_curve(RF_estimator, X_test_std, y_test, 10, 'Random Forest')\n",
    "                           \n",
    "SGD_estimator = sgd_gs.best_estimator_\n",
    "model_learning_curve(SGD_estimator, X_train_std, y_train, n_splits, 'SGD')\n",
    "\n",
    "\n",
    "print('Scores:',\n",
    "'\\nLR:', LR_estimator.score(X_test_std, y_test), \n",
    "'\\nSVM:', SVC_estimator.score(X_test_std, y_test), \n",
    "'\\nDT:', dt_estimator.score(X_test_std, y_test),  \n",
    "'\\nRF:', RF_estimator.score(X_test_std, y_test),\n",
    "'\\nSGD:', SGD_estimator.score(X_test_std, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
